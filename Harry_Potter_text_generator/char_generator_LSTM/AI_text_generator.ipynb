{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#TRAINING PIPELINE\nimport numpy as np\nimport time\nimport tensorflow as tf\nimport datetime\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorboard.plugins.hparams import api as hp\nfrom keras import backend as K\nfrom tensorflow.keras.utils import Sequence\nimport numpy as np\nimport math\n\n#PARAMETERS\nUNITS = 512\nDROPOUT = 0.1\nBATCH = 64\nLEN_SEQUENCE = 50\nEPOCH = 20\n\nclass data_sequence(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n\n        return batch_x, batch_y\n\n#DIRECTORIES    \nDATA_PATH = \"../input/harry-potter-all/Harry_Potter_all_modified_v3.txt\"\nSAVED_MODEL_PATH = \"../input/harry-potter-all/Best_weights.hdf5\"\nCHECKPOINT_PATH = \"Best_weights.hdf5\"\n\n#OPEN DATA\ntext = open(DATA_PATH, \"r\", encoding=\"utf-8\").read().lower()\n\n#DATA PREPARATION\nCHARS_IN_TEXT = len(text)\nALL_CHARS = sorted(set(text))\n\nchar_to_int = {char:i for i, char in enumerate(ALL_CHARS)}\nint_to_char = {v: k for k, v in char_to_int.items()}\n\nX = []\ny = []\n\nfor i in range(0, CHARS_IN_TEXT-LEN_SEQUENCE, 1):\n    sequence_X = text[i:i+LEN_SEQUENCE]\n    sequence_y = text[i+LEN_SEQUENCE]\n    X.append([char_to_int[c] for c in sequence_X])\n    y.append(char_to_int[sequence_y])   \n\npatterns = len(X)\n\nX_data = np.reshape(X, (patterns, LEN_SEQUENCE, 1))\nX_data = X_data.astype(\"float16\")       \nX_data = X_data/float(len(ALL_CHARS))\ny_data = np_utils.to_categorical(y)\n\n#CHECKPOINT INITIALIZATION\ncheckpoint = ModelCheckpoint(CHECKPOINT_PATH, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\n#STOP TRAINING IF NO IMPROVE\nearly_stop = tf.keras.callbacks.EarlyStopping(\"loss\", patience=2, restore_best_weights=True)\n\n#LOAD WEIGHTS(from dataset)\nsequence = data_sequence(X_data, y_data, BATCH)\nmodel = keras.models.load_model(SAVED_MODEL_PATH)\ntensorboard_log = tf.keras.callbacks.TensorBoard(f\"./{datetime.datetime.now().strftime('%d-%m-%y %H:%M')} L:{LEN_SEQUENCE}_U:{UNITS}_D:{DROPOUT}_B:{BATCH}\", histogram_freq=1)\n\n# START TREINING\nwhile True:\n    model.fit(sequence, epochs=EPOCH, callbacks=[checkpoint, tensorboard_log, early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:11:29.136724Z","iopub.execute_input":"2021-12-29T12:11:29.137441Z","iopub.status.idle":"2021-12-29T20:18:15.727308Z","shell.execute_reply.started":"2021-12-29T12:11:29.137343Z","shell.execute_reply":"2021-12-29T20:18:15.72359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TRAIN FROM SCRATCH\nimport numpy as np\nimport time\nimport tensorflow as tf\nimport datetime\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorboard.plugins.hparams import api as hp\nfrom tensorflow.keras.utils import Sequence\nimport numpy as np\nimport math\n\n#PARAMETERS\nUNITS = 512\nDROPOUT = 0.1\nBATCH = 64\nLEN_SEQUENCE = 50\nEPOCH = 20\n\nclass data_sequence(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n\n        return batch_x, batch_y\n\n#DIRECTORIES    \nDATA_PATH = \"../input/harry-potter-all/Harry_Potter_all_modified_v3.txt\"\nSAVED_MODEL_PATH = \"../input/harry-potter-lstm/Best_weights.hdf5\"\nCHECKPOINT_PATH = \"Best_weights.hdf5\"\n\n#OPEN DATA\ntext = open(DATA_PATH, \"r\", encoding=\"utf-8\").read().lower()\n\n#DATA PREPARATION\nCHARS_IN_TEXT = len(text)\nALL_CHARS = sorted(set(text))\n\nchar_to_int = {char:i for i, char in enumerate(ALL_CHARS)}\nint_to_char = {v: k for k, v in char_to_int.items()}\n\nX = []\ny = []\n\nfor i in range(0, CHARS_IN_TEXT-LEN_SEQUENCE, 1):\n    sequence_X = text[i:i+LEN_SEQUENCE]\n    sequence_y = text[i+LEN_SEQUENCE]\n    X.append([char_to_int[c] for c in sequence_X])\n    y.append(char_to_int[sequence_y])   \n\npatterns = len(X)\n\nX_data = np.reshape(X, (patterns, LEN_SEQUENCE, 1))\nX_data = X_data.astype(\"float16\")       \nX_data = X_data/float(len(ALL_CHARS))\ny_data = np_utils.to_categorical(y)\n\n#CREATE MODEL\nmodel = Sequential()\nmodel.add(LSTM(UNITS, input_shape=(X_data.shape[1], X_data.shape[2]), return_sequences=True))\nmodel.add(Dropout(DROPOUT))\nmodel.add(LSTM(UNITS))\nmodel.add(Dropout(DROPOUT))\nmodel.add(Dense(y_data.shape[1], activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n\n#CHECKPOINT INITIALIZATION\ncheckpoint = ModelCheckpoint(CHECKPOINT_PATH, monitor='loss', verbose=1, save_best_only=True, mode='min')\n\nsequence = data_sequence(X_data, y_data, BATCH)\ntensorboard_log = tf.keras.callbacks.TensorBoard(f\"./{datetime.datetime.now().strftime('%d-%m-%y %H:%M')} L:{LEN_SEQUENCE}_U:{UNITS}_D:{DROPOUT}_B:{BATCH}\", histogram_freq=1)\nmodel.fit(sequence, epochs=EPOCH, callbacks=[checkpoint, tensorboard_log])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T12:32:07.762626Z","iopub.execute_input":"2021-12-19T12:32:07.762972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#parametr tunning with tensorboard\n\n#PARAMETERS\nEPOCHS = 1\nHP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([128]))\nHP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.2]))\nHP_BATCH = hp.HParam('batch', hp.Discrete([2,4,8,16,32,64,128]))\nHP_TIME = hp.HParam('time')\nHP_SEQUENCE = hp.HParam('Len_sequence')\n\n#HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n\n#Directory to save logs\nlog_dir = \"./logs/\"\n\nwith tf.summary.create_file_writer(log_dir).as_default():\n    hp.hparams_config(\n        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_BATCH, HP_TIME, HP_SEQUENCE],\n        metrics=[\n        hp.Metric(tag=\"categorical_crossentropy\", display_name=\"Loss\")\n        ]\n    )\n        \n    \n#defining model with changing parameters    \ndef train_test_model(hparams, directory):\n    model = Sequential()\n    model.add(LSTM(hparams[HP_NUM_UNITS], input_shape=(X_data.shape[1], X_data.shape[2])))\n    model.add(Dropout(hparams[HP_DROPOUT]))\n    model.add(Dense(y_data.shape[1], activation=\"softmax\"))\n    model.compile(\n    optimizer=\"adam\",\n    loss='categorical_crossentropy'\n    )\n    sequence = data_sequence(X_data, y_data, hparams[HP_BATCH])\n    start_time = time.time()\n    history = model.fit(sequence, epochs=EPOCHS, callbacks=[tf.keras.callbacks.TensorBoard(f\"{directory}:{batch_size}\", histogram_freq=1)])\n    duration = time.time() - start_time\n    return history, duration\n\ndef run_experiment(directory, hparams):\n    with tf.summary.create_file_writer(directory).as_default():\n        hist, time = train_test_model(hparams, directory)\n        hparams[\"time\"] = (time)/EPOCHS\n        hparams[\"Len_sequence\"] = LEN_SEQUENCE\n        hp.hparams(hparams)\n        for step, loss in enumerate(hist.history[\"loss\"]):\n                tf.summary.scalar(\"categorical_crossentropy\", loss, step=step)\n\nsession_num = 0\n\n#training loop\nfor num_units in HP_NUM_UNITS.domain.values:\n    for dropout_rate in HP_DROPOUT.domain.values:\n        for batch_size in HP_BATCH.domain.values:\n            hparams = {\n                HP_NUM_UNITS: num_units,\n                HP_DROPOUT: dropout_rate,\n                HP_BATCH: batch_size\n                }\n            run_name = \"/run-%d\" % session_num\n            print('--- Starting trial: %s' % run_name)\n            print({h.name: hparams[h] for h in hparams})\n            run_experiment(log_dir+run_name, hparams)\n            \n            session_num += 1","metadata":{"execution":{"iopub.status.busy":"2021-12-13T16:08:50.086366Z","iopub.execute_input":"2021-12-13T16:08:50.086619Z","iopub.status.idle":"2021-12-13T17:45:58.027361Z","shell.execute_reply.started":"2021-12-13T16:08:50.086591Z","shell.execute_reply":"2021-12-13T17:45:58.026587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compress folder to zip file\nimport shutil\nshutil.make_archive(\"tensorboard\", 'zip', \"../\")","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:19:09.697433Z","iopub.execute_input":"2021-12-19T21:19:09.697842Z","iopub.status.idle":"2021-12-19T21:20:56.743553Z","shell.execute_reply.started":"2021-12-19T21:19:09.697717Z","shell.execute_reply":"2021-12-19T21:20:56.742216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change LR\nfrom keras import backend as K\nK.set_value(model.optimizer.learning_rate, 0.0001)\nmodel.optimizer.lr","metadata":{"execution":{"iopub.status.busy":"2021-12-14T16:00:26.04075Z","iopub.execute_input":"2021-12-14T16:00:26.041043Z","iopub.status.idle":"2021-12-14T16:00:26.049893Z","shell.execute_reply.started":"2021-12-14T16:00:26.040997Z","shell.execute_reply":"2021-12-14T16:00:26.049081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOAD DATA FOR TEXT GENERATION \nimport numpy as np\nimport keras\nfrom keras.utils import np_utils\n\n#DIRECTORIES    \nDATA_PATH = \"../input/harry-potter-all/Harry_Potter_all_modified_v3.txt\"\nSAVED_MODEL_PATH = \"../input/harry-potter-all/Best_weights.hdf5\"\n\n#OPEN DATA\ntext = open(DATA_PATH, \"r\", encoding=\"utf-8\").read().lower()\n\n#DATA PREPARATION\nCHARS_IN_TEXT = len(text)\nALL_CHARS = sorted(set(text))\nLEN_SEQUENCE = 50\n\nchar_to_int = {char:i for i, char in enumerate(ALL_CHARS)}\nint_to_char = {v: k for k, v in char_to_int.items()}\n\nX = []\ny = []\n\nfor i in range(0, CHARS_IN_TEXT-LEN_SEQUENCE, 1):\n    sequence_X = text[i:i+LEN_SEQUENCE]\n    sequence_y = text[i+LEN_SEQUENCE]\n    X.append([char_to_int[c] for c in sequence_X])\n    y.append(char_to_int[sequence_y])   \n\npatterns = len(X)\n\nX_data = np.reshape(X, (patterns, LEN_SEQUENCE, 1))\nX_data = X_data.astype(\"float16\")       \nX_data = X_data/float(len(ALL_CHARS))\ny_data = np_utils.to_categorical(y)\n\nmodel = keras.models.load_model(SAVED_MODEL_PATH)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-01-02T20:56:39.497475Z","iopub.execute_input":"2022-01-02T20:56:39.498527Z","iopub.status.idle":"2022-01-02T20:58:01.642535Z","shell.execute_reply.started":"2022-01-02T20:56:39.498378Z","shell.execute_reply":"2022-01-02T20:58:01.631823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GENERATE TEXT\nimport sys\ndef temp_index(preds, temperature=1.0):\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds[0], 1)\n    return np.argmax(probas)\n\nstart = np.random.randint(0, len(X)-1)\npattern = X[start]\nprint(\"Seed:\")\nprint(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\nprint(\"\")\ntemperature = 0.4 #LOWER VALUE-MORE GENERIC/REPETITIVE/PREDICTIVE TEXT : HIGHER VALUE-MORE SUPRISING/UNPREDICTABLE TEXT\nfor i in range(500):\n    x = np.reshape(pattern, (1, len(pattern), 1))\n    x = x / float(len(ALL_CHARS))\n    prediction = model.predict(x, verbose=0)\n    index = temp_index(prediction, temperature)\n    result = int_to_char[index]\n    seq_in = [int_to_char[value] for value in pattern]\n    sys.stdout.write(result)\n    pattern.append(index)\n    pattern = pattern[1:len(pattern)]\nprint(\"\\nDone.\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T21:17:26.42071Z","iopub.execute_input":"2022-01-02T21:17:26.421087Z","iopub.status.idle":"2022-01-02T21:18:06.787977Z","shell.execute_reply.started":"2022-01-02T21:17:26.421038Z","shell.execute_reply":"2022-01-02T21:18:06.786803Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
